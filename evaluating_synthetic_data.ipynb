{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG+FuN7AMcEbxHo3pMw0bo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scaairesearch/da_cv_fer/blob/main/evaluating_synthetic_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnNnfiNZUiEW",
        "outputId": "188860f1-ed32-4b8f-9fa1-d96b9c4bcb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'da_cv_fer'...\n",
            "remote: Enumerating objects: 352, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 352 (delta 70), reused 67 (delta 32), pack-reused 209\u001b[K\n",
            "Receiving objects: 100% (352/352), 22.11 MiB | 21.73 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n"
          ]
        }
      ],
      "source": [
        "#@title loading libraries\n",
        "!git clone https://github.com/scaairesearch/da_cv_fer.git\n",
        "import os\n",
        "os.getcwd()\n",
        "os.chdir('da_cv_fer')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt # -q is for quiet install\n",
        "# for some reason the below does not get installed with requirements\n",
        "!pip install -q opendatasets\n",
        "!pip install -q facenet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8G9yqaBUtyR",
        "outputId": "70352d56-180a-420c-c02a-eb5cf2e14a3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==306 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==306\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title loading libraries\n",
        "from da_cv_fer.data_config import DataConfig\n",
        "from da_cv_fer.ds_sfew import DatasetSFEW\n",
        "from da_cv_fer.ds_sfew_crop import DatasetSFEWCROP\n",
        "from da_cv_fer.ds_expw_crop import EXPWCROP\n",
        "from da_cv_fer.ds_expw import EXPW\n",
        "from da_cv_fer.utils import *\n",
        "from da_cv_fer.model_DANN import DANN\n",
        "from da_cv_fer.model_DANN_Bespoke import DANNBespoke\n",
        "from da_cv_fer.run_config import RunConfig\n",
        "from da_cv_fer.train import *\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from tqdm import tqdm # for beautiful model training updates\n",
        "\n",
        "import matplotlib.pyplot as plt # for plots\n",
        "\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "from copy import deepcopy\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "5FZlTuKvUtGI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEQma-BWVq_O",
        "outputId": "96011802-94fb-487d-8eac-abcc5ad5707d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mounting Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9y3aCFDXjCW",
        "outputId": "72e8d4d2-9e73-491c-ae34-e4e6d563e691"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loading models to evaluate\n",
        "non_dann_model_sfew_name =  'non_dann_sfew_expw_03_03.pt'\n",
        "dataconfig_inference = DataConfig()"
      ],
      "metadata": {
        "id": "LWKvvexBVtvd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NON DANN\n",
        "\n",
        "non_dann_model_inference  = DANNBespoke(num_classes=7,backbone='mobilenet', attention=False, dropout = 0)\n",
        "# model_dir = Path('/content/gdrive/MyDrive/CV_FER/models/non_dann_sfew_expw')\n",
        "NON_DANN_SFEW_DIR = Path(dataconfig_inference.MODEL_DIR,\"non_dann_sfew_expw\") # Path(self.MODEL_DIR,\"non_dann_sfew\")\n",
        "\n",
        "try:\n",
        "    non_dann_model_inference.load_state_dict(torch.load(Path(NON_DANN_SFEW_DIR, non_dann_model_sfew_name),\n",
        "                                                        map_location=torch.device(device)))\n",
        "    print(f'{non_dann_model_sfew_name} locked and loaded')\n",
        "except Exception as e:\n",
        "    print(f' problem in loading {non_dann_model_sfew_name} {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUkNtZWbWWAM",
        "outputId": "1ba0c5fd-ac87-4a91-cd90-0eb19b783f10"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature extractor backbone created using mobilenet model\n",
            "non_dann_sfew_expw_03_03.pt locked and loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get SFEW Dataset\n",
        "\n",
        "sfew = DatasetSFEWCROP()\n",
        "sfew_train_loader, sfew_val_loader = sfew.get_dataloader()\n",
        "print(f' length of SFEW dataset : {len(sfew_train_loader.dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc8P8iwgWjfb",
        "outputId": "8855c619-f4c3-46f8-f524-ab603aa3521e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " self.BASE_PATH -dataset, \n",
            " self.EXTRACT_DIR-dataset/sfew,\n",
            " self.ZIP_FILE_PATH - dataset/SFEW_2.zip \n",
            "Directory dataset/sfew created successfully.\n",
            "No files (including zip file) found in dataset/sfew.Copying file\n",
            "Starting File copying from /content/gdrive/MyDrive/CV_FER/dataset/SFEW_2.zip to dataset/sfew\n",
            "File copied successfully from /content/gdrive/MyDrive/CV_FER/dataset/SFEW_2.zip to dataset/sfew\n",
            "Initiating extraction of dataset/sfew/SFEW_2.zip to dataset/sfew\n",
            "...completed for dataset/sfew/SFEW_2.zip\n",
            "dataset/sfew/Train Sad.zip Sad\n",
            "...completed for dataset/sfew/Train/Sad.zip\n",
            "dataset/sfew/Train Surprise.zip Surprise\n",
            "...completed for dataset/sfew/Train/Surprise.zip\n",
            "dataset/sfew/Train Angry.zip Angry\n",
            "...completed for dataset/sfew/Train/Angry.zip\n",
            "dataset/sfew/Train Disgust.zip Disgust\n",
            "...completed for dataset/sfew/Train/Disgust.zip\n",
            "dataset/sfew/Train Fear.zip Fear\n",
            "...completed for dataset/sfew/Train/Fear.zip\n",
            "dataset/sfew/Train Neutral.zip Neutral\n",
            "...completed for dataset/sfew/Train/Neutral.zip\n",
            "dataset/sfew/Train Happy.zip Happy\n",
            "...completed for dataset/sfew/Train/Happy.zip\n",
            "dataset/sfew/Val Sad.zip Sad\n",
            "...completed for dataset/sfew/Val/Sad.zip\n",
            "dataset/sfew/Val Surprise.zip Surprise\n",
            "...completed for dataset/sfew/Val/Surprise.zip\n",
            "dataset/sfew/Val Angry.zip Angry\n",
            "...completed for dataset/sfew/Val/Angry.zip\n",
            "dataset/sfew/Val Disgust.zip Disgust\n",
            "...completed for dataset/sfew/Val/Disgust.zip\n",
            "dataset/sfew/Val Fear.zip Fear\n",
            "...completed for dataset/sfew/Val/Fear.zip\n",
            "dataset/sfew/Val Neutral.zip Neutral\n",
            "...completed for dataset/sfew/Val/Neutral.zip\n",
            "dataset/sfew/Val Happy.zip Happy\n",
            "...completed for dataset/sfew/Val/Happy.zip\n",
            "Directory created: dataset/sfew/Train_Crop\n",
            "Directory created: dataset/sfew/Val_Crop\n",
            "98 cropped images created in Fear\n",
            "150 cropped images created in Neutral\n",
            "96 cropped images created in Surprise\n",
            "172 cropped images created in Sad\n",
            "178 cropped images created in Angry\n",
            "66 cropped images created in Disgust\n",
            "198 cropped images created in Happy\n",
            "47 cropped images created in Fear\n",
            "86 cropped images created in Neutral\n",
            "57 cropped images created in Surprise\n",
            "73 cropped images created in Sad\n",
            "77 cropped images created in Angry\n",
            "23 cropped images created in Disgust\n",
            "73 cropped images created in Happy\n",
            "----------mean_ds = [0.2197, 0.1858, 0.1569], std_dev_ds = [0.181, 0.1635, 0.1511]----------\n",
            " length of SFEW dataset : 912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_dann_model_inference.eval()\n",
        "all_preds = []\n",
        "all_gts =[]\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in sfew_val_loader:\n",
        "    images, labels = batch[0].to(device), batch[1].to(device)\n",
        "    class_output,_,_ = non_dann_model_inference(images)\n",
        "    label_gts = labels.argmax(dim=1)\n",
        "    label_preds = class_output.argmax(dim=1)\n",
        "    all_gts.extend(label_gts.cpu().numpy())\n",
        "    all_preds.extend(label_preds.cpu().numpy())"
      ],
      "metadata": {
        "id": "2dqZH3UCYoNI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map={0:\"Angry\",\n",
        "            1:\"Disgust\",\n",
        "            2:\"Fear\",\n",
        "            3:\"Happy\",\n",
        "            4:\"Sad\",\n",
        "            5:\"Surprise\",\n",
        "            6:\"Neutral\"}\n",
        "all_preds = [labels_map[int_label] for int_label in all_preds]\n",
        "all_gts= [labels_map[int_label] for int_label in all_gts]\n",
        "\n",
        "all_preds, all_gts"
      ],
      "metadata": {
        "id": "eJw0MvWtbkJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Calculate performance metrics\n",
        "accuracy = (np.array(all_preds) == np.array(all_gts)).mean()\n",
        "classification_rep = classification_report(all_gts, all_preds)"
      ],
      "metadata": {
        "id": "lFTcvzB4cTYA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j5BIEMydmVX",
        "outputId": "b5595883-e171-404d-b1a3-4b1286042f0c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45584725536992843\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.43      0.77      0.55        75\n",
            "     Disgust       0.23      0.32      0.27        22\n",
            "        Fear       0.19      0.12      0.14        43\n",
            "       Happy       0.65      0.71      0.68        72\n",
            "     Neutral       0.33      0.17      0.23        52\n",
            "         Sad       0.45      0.48      0.47        84\n",
            "    Surprise       0.62      0.30      0.40        71\n",
            "\n",
            "    accuracy                           0.46       419\n",
            "   macro avg       0.42      0.41      0.39       419\n",
            "weighted avg       0.46      0.46      0.43       419\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_gts = np.array(all_gts)\n",
        "all_preds = np.array(all_preds)\n",
        "\n",
        "# Get unique classes in the dataset\n",
        "unique_classes = np.unique(all_gts)\n",
        "\n",
        "# Initialize arrays to store class-wise correct predictions and total samples\n",
        "class_correct = np.zeros(len(unique_classes))\n",
        "class_total = np.zeros(len(unique_classes))\n",
        "\n",
        "# Iterate over each unique class\n",
        "for i, cls in enumerate(unique_classes):\n",
        "    # Filter predictions and labels for the current class\n",
        "    class_preds = all_preds[all_gts == cls]\n",
        "    class_labels = all_gts[all_gts == cls]\n",
        "\n",
        "    # Calculate accuracy for the current class\n",
        "    class_correct[i] = np.sum(class_preds == class_labels)\n",
        "    class_total[i] = len(class_labels)\n",
        "\n",
        "# Print accuracy for each class\n",
        "for i, cls in enumerate(unique_classes):\n",
        "    if class_total[i] > 0:\n",
        "        accuracy = 100 * class_correct[i] / class_total[i]\n",
        "        print(f'Accuracy for class {cls}: {accuracy:.2f}% (Total Correct: {int(class_correct[i])}/{int(class_total[i])})')\n",
        "    else:\n",
        "        print(f'Accuracy for class {cls}: N/A (No samples in this class)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr_KlYfbdpLt",
        "outputId": "c267580e-c260-44cd-bbe2-c3d657c77abf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class Angry: 77.33% (Total Correct: 58/75)\n",
            "Accuracy for class Disgust: 31.82% (Total Correct: 7/22)\n",
            "Accuracy for class Fear: 11.63% (Total Correct: 5/43)\n",
            "Accuracy for class Happy: 70.83% (Total Correct: 51/72)\n",
            "Accuracy for class Neutral: 17.31% (Total Correct: 9/52)\n",
            "Accuracy for class Sad: 47.62% (Total Correct: 40/84)\n",
            "Accuracy for class Surprise: 29.58% (Total Correct: 21/71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hCMc5IMhJ4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}